{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complex-accountability",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bace_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dca83bffe0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbace_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_bace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperparamOpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bace_datasets'"
     ]
    }
   ],
   "source": [
    "\"\"\"This example implements RF experiments from https://pubs.acs.org/doi/abs/10.1021/acs.jcim.6b00290\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import deepchem\n",
    "import deepchem as dc\n",
    "import tempfile, shutil\n",
    "from bace_datasets import load_bace\n",
    "from deepchem.hyper import HyperparamOpt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deepchem.models.sklearn_models import SklearnModel\n",
    "from deepchem import metrics\n",
    "from deepchem.metrics import Metric\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "\n",
    "\n",
    "def bace_rf_model(mode=\"classification\", split=\"20-80\"):\n",
    "  \"\"\"Train random forests on BACE dataset.\"\"\"\n",
    "  (bace_tasks, (train, valid, test, crystal), transformers) = load_bace(\n",
    "      mode=mode, transform=False, split=split)\n",
    "\n",
    "  if mode == \"regression\":\n",
    "    r2_metric = Metric(metrics.r2_score)\n",
    "    rms_metric = Metric(metrics.rms_score)\n",
    "    mae_metric = Metric(metrics.mae_score)\n",
    "    all_metrics = [r2_metric, rms_metric, mae_metric]\n",
    "    metric = r2_metric\n",
    "    model_class = RandomForestRegressor\n",
    "\n",
    "    def rf_model_builder(model_params, model_dir):\n",
    "      sklearn_model = RandomForestRegressor(**model_params)\n",
    "      return SklearnModel(sklearn_model, model_dir)\n",
    "  elif mode == \"classification\":\n",
    "    roc_auc_metric = Metric(metrics.roc_auc_score)\n",
    "    accuracy_metric = Metric(metrics.accuracy_score)\n",
    "    mcc_metric = Metric(metrics.matthews_corrcoef)\n",
    "    # Note sensitivity = recall\n",
    "    recall_metric = Metric(metrics.recall_score)\n",
    "    model_class = RandomForestClassifier\n",
    "    all_metrics = [accuracy_metric, mcc_metric, recall_metric, roc_auc_metric]\n",
    "    metric = roc_auc_metric\n",
    "\n",
    "    def rf_model_builder(model_params, model_dir):\n",
    "      sklearn_model = RandomForestClassifier(**model_params)\n",
    "      return SklearnModel(sklearn_model, model_dir)\n",
    "  else:\n",
    "    raise ValueError(\"Invalid mode %s\" % mode)\n",
    "\n",
    "  params_dict = {\n",
    "      \"n_estimators\": [10, 100],\n",
    "      \"max_features\": [\"auto\", \"sqrt\", \"log2\", None],\n",
    "  }\n",
    "\n",
    "  optimizer = HyperparamOpt(rf_model_builder)\n",
    "  best_rf, best_rf_hyperparams, all_rf_results = optimizer.hyperparam_search(\n",
    "      params_dict, train, valid, transformers, metric=metric)\n",
    "\n",
    "  if len(train) > 0:\n",
    "    rf_train_evaluator = Evaluator(best_rf, train, transformers)\n",
    "    csv_out = \"rf_%s_%s_train.csv\" % (mode, split)\n",
    "    stats_out = \"rf_%s_%s_train_stats.txt\" % (mode, split)\n",
    "    rf_train_score = rf_train_evaluator.compute_model_performance(\n",
    "        all_metrics, csv_out=csv_out, stats_out=stats_out)\n",
    "    print(\"RF Train set scores: %s\" % (str(rf_train_score)))\n",
    "\n",
    "  if len(valid) > 0:\n",
    "    rf_valid_evaluator = Evaluator(best_rf, valid, transformers)\n",
    "    csv_out = \"rf_%s_%s_valid.csv\" % (mode, split)\n",
    "    stats_out = \"rf_%s_%s_valid_stats.txt\" % (mode, split)\n",
    "    rf_valid_score = rf_valid_evaluator.compute_model_performance(\n",
    "        all_metrics, csv_out=csv_out, stats_out=stats_out)\n",
    "    print(\"RF Valid set scores: %s\" % (str(rf_valid_score)))\n",
    "\n",
    "  if len(test) > 0:\n",
    "    rf_test_evaluator = Evaluator(best_rf, test, transformers)\n",
    "    csv_out = \"rf_%s_%s_test.csv\" % (mode, split)\n",
    "    stats_out = \"rf_%s_%s_test_stats.txt\" % (mode, split)\n",
    "    rf_test_score = rf_test_evaluator.compute_model_performance(\n",
    "        all_metrics, csv_out=csv_out, stats_out=stats_out)\n",
    "    print(\"RF Test set: %s\" % (str(rf_test_score)))\n",
    "\n",
    "  if len(crystal) > 0:\n",
    "    rf_crystal_evaluator = Evaluator(best_rf, crystal, transformers)\n",
    "    csv_out = \"rf_%s_%s_crystal.csv\" % (mode, split)\n",
    "    stats_out = \"rf_%s_%s_crystal_stats.txt\" % (mode, split)\n",
    "    rf_crystal_score = rf_crystal_evaluator.compute_model_performance(\n",
    "        all_metrics, csv_out=csv_out, stats_out=stats_out)\n",
    "    print(\"RF Crystal set: %s\" % (str(rf_crystal_score)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  print(\"Classifier RF 20-80:\")\n",
    "  print(\"--------------------------------\")\n",
    "  bace_rf_model(mode=\"classification\", split=\"20-80\")\n",
    "  print(\"Classifier RF 80-20:\")\n",
    "  print(\"--------------------------------\")\n",
    "  bace_rf_model(mode=\"classification\", split=\"80-20\")\n",
    "\n",
    "  print(\"Regressor RF 20-80:\")\n",
    "  print(\"--------------------------------\")\n",
    "  bace_rf_model(mode=\"regression\", split=\"20-80\")\n",
    "  print(\"Regressor RF 80-20:\")\n",
    "  print(\"--------------------------------\")\n",
    "  bace_rf_model(mode=\"regression\", split=\"80-20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "portuguese-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-s SPLITTER_ARGS] [-m MODEL_ARGS]\n",
      "                             [-d DATASET_ARGS] [-t] [--seed SEED_ARGS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/ella/.local/share/jupyter/runtime/kernel-6589eac0-f5d7-4481-bb12-35b567c43963.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "##!/usr/bin/env python3\n",
    "## -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Oct 18 15:53:27 2016\n",
    "\n",
    "@author: Michael Wu\n",
    "\n",
    "Benchmark test:\n",
    "\n",
    "Giving classification performances of:\n",
    "    Random forest(rf), MultitaskDNN(tf),\n",
    "    RobustMultitaskDNN(tf_robust),\n",
    "    Logistic regression(logreg), IRV(irv)\n",
    "    Graph convolution(graphconv), xgboost(xgb),\n",
    "    Directed acyclic graph(dag), Weave(weave)\n",
    "on datasets: bace_c, bbbp, clintox, hiv, muv, pcba, sider, tox21, toxcast\n",
    "\n",
    "Giving regression performances of:\n",
    "    MultitaskDNN(tf_regression),\n",
    "    Fit Transformer MultitaskDNN(tf_regression_ft),\n",
    "    Random forest(rf_regression),\n",
    "    Graph convolution regression(graphconvreg),\n",
    "    xgboost(xgb_regression), Deep tensor neural net(dtnn),\n",
    "    Directed acyclic graph(dag_regression),\n",
    "    Weave(weave_regression)\n",
    "on datasets: bace_r, chembl, clearance, delaney(ESOL), hopv, kaggle, lipo,\n",
    "             nci, pdbbind, ppb, qm7, qm7b, qm8, qm9, sampl(FreeSolv)\n",
    "\n",
    "Hyperparameters and all benchmark scripts for MoleculeNet are available at:\n",
    "http://deepchem.io.s3-website-us-west-1.amazonaws.com/trained_models/Hyperparameter_MoleculeNetv3.tar.gz\n",
    "\n",
    "\"\"\"\n",
    "#from __future__ import print_function\n",
    "#from __future__ import division\n",
    "#from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Deepchem benchmark: ' +\n",
    "    'giving performances of different learning models on datasets')\n",
    "parser.add_argument(\n",
    "    '-s',\n",
    "    action='append',\n",
    "    dest='splitter_args',\n",
    "    default=[],\n",
    "    help='Choice of splitting function: index, random, scaffold, stratified')\n",
    "parser.add_argument(\n",
    "    '-m',\n",
    "    action='append',\n",
    "    dest='model_args',\n",
    "    default=[],\n",
    "    help='Choice of model: tf, tf_robust, logreg, rf, irv, graphconv, xgb,' + \\\n",
    "         ' dag, weave, tf_regression, tf_regression_ft, rf_regression, ' + \\\n",
    "         'graphconvreg, xgb_regression, dtnn, dag_regression, weave_regression')\n",
    "parser.add_argument(\n",
    "    '-d',\n",
    "    action='append',\n",
    "    dest='dataset_args',\n",
    "    default=[],\n",
    "    help='Choice of dataset: bace_c, bace_r, bbbp, chembl, clearance, ' +\n",
    "    'clintox, delaney, hiv, hopv, kaggle, lipo, muv, nci, pcba, pcba_146, pcba_2475 '\n",
    "    + 'pdbbind, ppb, qm7, qm7b, qm8, qm9, sampl, sider, tox21, toxcast')\n",
    "parser.add_argument(\n",
    "    '-t',\n",
    "    action='store_true',\n",
    "    dest='test',\n",
    "    default=False,\n",
    "    help='Evalute performance on test set')\n",
    "parser.add_argument(\n",
    "    '--seed',\n",
    "    action='append',\n",
    "    dest='seed_args',\n",
    "    default=[],\n",
    "    help='Choice of random seed')\n",
    "args = parser.parse_args()\n",
    "#Datasets and models used in the benchmark test\n",
    "splitters = args.splitter_args\n",
    "models = args.model_args\n",
    "datasets = args.dataset_args\n",
    "test = args.test\n",
    "if len(args.seed_args) > 0:\n",
    "  seed = int(args.seed_args[0])\n",
    "else:\n",
    "  seed = 123\n",
    "\n",
    "if len(splitters) == 0:\n",
    "  splitters = ['index', 'random', 'scaffold']\n",
    "if len(models) == 0:\n",
    "  models = [\n",
    "      'tf', 'tf_robust', 'logreg', 'graphconv', 'irv', 'tf_regression',\n",
    "      'tf_regression_ft', 'graphconvreg', 'weave', 'weave_regression', 'dtnn'\n",
    "  ]\n",
    "  #irv, rf, rf_regression should be assigned manually\n",
    "if len(datasets) == 0:\n",
    "  datasets = [\n",
    "      'bace_c', 'bace_r', 'bbbp', 'clearance', 'clintox', 'delaney', 'hiv',\n",
    "      'hopv', 'lipo', 'muv', 'pdbbind', 'ppb', 'qm7b', 'qm8', 'qm9', 'sampl',\n",
    "      'sider', 'tox21', 'toxcast'\n",
    "  ]\n",
    "\n",
    "for dataset in datasets:\n",
    "  for split in splitters:\n",
    "    for model in models:\n",
    "      np.random.seed(seed)\n",
    "      dc.molnet.run_benchmark(\n",
    "          [dataset], str(model), split=split, test=test, seed=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-benjamin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_for_chemists] *",
   "language": "python",
   "name": "conda-env-ml_for_chemists-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
