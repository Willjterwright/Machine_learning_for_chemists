{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Using DeepChem\n",
    "\n",
    "This is the last notebook to do as part of this course (reinforcement learning, which is the missing third of ML is currently used less for ML, but keep an eye out for it being used more in retrosynthesis in the future). \n",
    "\n",
    "At this point, I thought I would give you some resources to continue learning from: \n",
    "\n",
    "*Paid*\n",
    "\n",
    "1. O'Reilly, 'Hands on machine learning with scikit-learn and tensorflow (2nd edition), Aurelien Geron\n",
    "https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\n",
    "If you were to buy one ML textbook I would get this one. It's about £40. Make sure you get the 2nd edition as that includes tensorflow2 which is the newer (and ever so much easier to use) version of tensorflow. The code used in the textbook is here: https://github.com/ageron/handson-ml2\n",
    "\n",
    "2. O-Reilly, /'Deep learning for the life sciences'/\n",
    "https://www.oreilly.com/library/view/deep-learning-for/9781492039822/\n",
    "This is OK, it has some nice deepchem examples, however, the book is rather short and half of it is biology related, so this is best a book that is borrowed from the library\n",
    "\n",
    "*Free*\n",
    "\n",
    "1. DeepChem's tutorials: \n",
    "https://github.com/deepchem/deepchem/tree/master/examples\n",
    "Download or pull these and run them in the environment set up for these notebooks. They will introduce you to deepchem and covers more material than this course was able to \n",
    "\n",
    "2. Deep Learning for hte life sciences example code\n",
    "https://github.com/deepchem/DeepLearningLifeSciences\n",
    "The code from the book above. Useful to look at if you're not able to borrow the book. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepChem\n",
    "\n",
    "DeepChem[1,2] is a lovely module that has only recently appeared, and it will make using ML for chemistry so much easier! In this section we shall play with it and try to solve some chemical problems.\n",
    "\n",
    "\n",
    "MoleculeNet [3,4] is a series of _benchmark_ datasets for chemistry, these are standard datasets that people can use to test their algorithms against. Also, they are problems worth solving in their own right. \n",
    "\n",
    "Tensorflow [5] is a ML package that we met in the previous workbook, it is powerful and useful, however writing tensorflow code directly is fiddly (as least I think so!)\n",
    "\n",
    "Keras [6] is a module for writing, training and testing ML/neural networks (NN), it will write the correct tensorflow code for you. \n",
    "\n",
    "DeepChem contains both keras and tensorflow, so you can use those modules from within it. \n",
    "\n",
    "rdkit is a general purpose computational chemistry module which we will use for plotting molecules, but you can also use it to calculate molecular properties.\n",
    "\n",
    "[1] https://deepchem.io/\n",
    "\n",
    "[2] https://github.com/deepchem\n",
    "\n",
    "[3] Wu, Zhenqin, et al. \"MoleculeNet: a benchmark for molecular machine learning.\" Chemical science 9.2 (2018): 513-530.\n",
    "\n",
    "[4] https://deepchem.readthedocs.io/en/latest/moleculenet.html\n",
    "\n",
    "[5] https://keras.io/\n",
    "[6] https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load our libraries\n",
    "import deepchem as dc\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is when the algorithm is given the answer (target) to learn from. Essentially, the algorithm is given in the input data, it guesses a solution to get a prediction (output), and this is compared to the correct answer. Obviously the first guess is wrong, but by comparing the prediction (**\\hat{y}**) to the true answer, *target* or *ground truth* (**y**) the model can *learn* and improve its predictions.\n",
    "\n",
    "Supervised learning models *fit* a *function* from *features*(**X**) to *target(s)* (**y**). For example, the features may be a set of *fingerprints* (created from a chemical structure) and the target may be a molecular property, like atomic energy, solubility, or action against a protein target.\n",
    "\n",
    "There are many supervised learning algorithms, but most the recent breakthroughs in ML have come from **neural networks** and this is what we will concentrate on here. This notebook contains chemical models, see 4_Supervised_Learning for neural networks applied to standard NN problems (vision) to help you understand how NNs work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of problems: \n",
    "\n",
    "#### Regression\n",
    "\n",
    "The regression discussed here is exactly the same as that in notebooks 1 and 2a, however as the input data is highly multidimentional (often 1000's of dimensions), the fitted function is a multi-dimensional object, for this reason we do not plot the fitted function (as we did in the Linear_Regression_Cellulose notebook). Instead, we are interested in how well the model *predicts* the training set data, and *generalises* to the test data. \n",
    "\n",
    "Regression models can be thought of as fitting a function:\n",
    "$$\n",
    "\\textbf{X} \\rightarrow Model \\rightarrow \\textbf{y}\n",
    "$$\n",
    "\n",
    "where **y** is usually a number. \n",
    "\n",
    "#### Classificiation\n",
    "\n",
    "Classification models assign input data to a *category*. For example, matching a molecular structure to the category 'active against HIV protein'. See notebook 4 for more examples. \n",
    "\n",
    "#### Generation\n",
    "\n",
    "Generative models produce new examples of the input after training. For example, you might train a variational autoencoder on molecular structures and then use it to generate novel molecular structures. \n",
    "\n",
    "In this document we shall train some regression and classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delaney Dataset\n",
    "\n",
    "The Delaney (ESOL) dataset a regression dataset containing structures and water solubility data for 1128 compounds. The dataset is widely used to validate machine learning models on estimating solubility directly from molecular structures (as encoded in SMILES strings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepChem has methods to load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='ECFP')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some example data from the test set. There are 1049 features generated from the SMILES strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>w11</th>\n",
       "      <th>w12</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053182</td>\n",
       "      <td>1.154005</td>\n",
       "      <td>1.055911</td>\n",
       "      <td>1.027652</td>\n",
       "      <td>1.183902</td>\n",
       "      <td>1.035773</td>\n",
       "      <td>1.056524</td>\n",
       "      <td>1.194263</td>\n",
       "      <td>1.057867</td>\n",
       "      <td>CC1=CC(=O)CC(C)(C)C1(O)/C=C/C(C)=C\\C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.493314</td>\n",
       "      <td>1.055911</td>\n",
       "      <td>1.027652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.194263</td>\n",
       "      <td>1.057867</td>\n",
       "      <td>Cc1cc(C(=O)NNCc2ccccc2)no1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053182</td>\n",
       "      <td>1.154005</td>\n",
       "      <td>1.055911</td>\n",
       "      <td>1.027652</td>\n",
       "      <td>1.183902</td>\n",
       "      <td>1.035773</td>\n",
       "      <td>1.056524</td>\n",
       "      <td>1.194263</td>\n",
       "      <td>1.057867</td>\n",
       "      <td>Cl[Zn]Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.055911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.437669</td>\n",
       "      <td>1.035773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.057867</td>\n",
       "      <td>CCOc1cc(C(C)(C)C)ccc1C1COC(c2c(F)cccc2F)=N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.027652</td>\n",
       "      <td>6.437669</td>\n",
       "      <td>1.035773</td>\n",
       "      <td>1.056524</td>\n",
       "      <td>1.194263</td>\n",
       "      <td>1.057867</td>\n",
       "      <td>CCOC1Oc2ccc(OS(C)(=O)=O)cc2C1(C)C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1   X2   X3   X4   X5   X6   X7   X8   X9  X10  ...        w4        w5  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.053182  1.154005   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000  7.493314   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.053182  1.154005   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.000000  0.000000   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.053182  0.000000   \n",
       "\n",
       "         w6        w7        w8        w9       w10       w11       w12  \\\n",
       "0  1.055911  1.027652  1.183902  1.035773  1.056524  1.194263  1.057867   \n",
       "1  1.055911  1.027652  0.000000  1.035773  0.000000  1.194263  1.057867   \n",
       "2  1.055911  1.027652  1.183902  1.035773  1.056524  1.194263  1.057867   \n",
       "3  1.055911  0.000000  6.437669  1.035773  0.000000  0.000000  1.057867   \n",
       "4  0.000000  1.027652  6.437669  1.035773  1.056524  1.194263  1.057867   \n",
       "\n",
       "                                           ids  \n",
       "0    CC1=CC(=O)CC(C)(C)C1(O)/C=C/C(C)=C\\C(=O)O  \n",
       "1                   Cc1cc(C(=O)NNCc2ccccc2)no1  \n",
       "2                                     Cl[Zn]Cl  \n",
       "3  CCOc1cc(C(C)(C)C)ccc1C1COC(c2c(F)cccc2F)=N1  \n",
       "4            CCOC1Oc2ccc(OS(C)(=O)=O)cc2C1(C)C  \n",
       "\n",
       "[5 rows x 1049 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (113, 1024), y.shape: (113, 1), w.shape: (113, 1), ids: ['c1cc2ccc3cccc4ccc(c1)c2c34' 'Cc1cc(=O)[nH]c(=S)[nH]1'\n",
      " 'Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 ' ...\n",
      " 'c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43' 'Cc1occc1C(=O)Nc2ccccc2'\n",
      " 'OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O '], task_names: ['measured log solubility in mols per litre']>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE ABOUT RF HERE !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets the RandomForestRegerssor model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF_model = RandomForestRegressor(n_estimators=100)\n",
    "#dir(dc.models)\n",
    "model = dc.models.SklearnModel(RF_model)\n",
    "model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'pearson_r2_score': 0.9511910349070802}\n",
      "Test set score: {'pearson_r2_score': 0.4756801401182071}\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look, a molecule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'molecule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c53743ac53a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mChem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmolecule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'molecule' is not defined"
     ]
    }
   ],
   "source": [
    "Chem.MolFromSmiles(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mol_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-db016ac6a2e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mChem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmol_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mDraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMolsToGridImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mol_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ms = [Chem.MolFromSmiles(x) for x in mol_list]\n",
    "Draw.MolsToGridImage(ms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph convolution networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ella/anaconda3/envs/ml_for_chemists/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1087474536895752"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: {'pearson_r2_score': 0.9262812405775629}\n",
      "Test set score: {'pearson_r2_score': 0.6816329411723037}\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9073966] c1cc2ccc3cccc4ccc(c1)c2c34\n",
      "[0.4217861] Cc1cc(=O)[nH]c(=S)[nH]1\n",
      "[-0.8633107] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
      "[-2.0834172] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
      "[-1.3689758] C1=Cc2cccc3cccc1c23\n",
      "[1.4357395] CC1CO1\n",
      "[-0.7201981] CCN2c1ccccc1N(C)C(=S)c3cccnc23 \n",
      "[-1.0244131] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O\n",
      "[-1.3317294] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F\n",
      "[-0.13841814] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl \n"
     ]
    }
   ],
   "source": [
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "mol_list=[]\n",
    "for molecule, solubility in zip(test_dataset.ids, solubilities):\n",
    "    print(solubility, molecule)\n",
    "    mol_list.append(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measured log solubility in mols per litre']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making your own models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will write our own keras code to create different neural networks and see which is best for solving the delaney dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='ECFP', splitter='random')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model = dc.models.KerasModel(keras_model, dc.models.losses.L1Loss())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'pearson_r2_score': 0.8694946328487405}\n",
      "test set score: {'pearson_r2_score': 0.634376666378724}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(train_dataset, nb_epoch=50)\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Things to add:\n",
    "\n",
    "*layers*\n",
    "1. tf.keras.layers.Dense(1000, activation='relu')\n",
    "2. tf.keras.layers.Dropout(rate=0.5)\n",
    "3. tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "You can change the number of neurons: \n",
    "`tf.keras.layers.Dense(*1000*, activation='relu')` --> `tf.keras.layers.Dense(*200*, activation='relu')`\n",
    "\n",
    "You can change the activation function:\n",
    "`tf.keras.layers.Dense(1000, activation=*'relu'*)` --> `tf.keras.layers.Dense(1000, activation=*'sigmoid'*)`\n",
    "\n",
    "You can add in normalisation or [[]] layers:\n",
    "`tf.keras.layers.Dropout(rate=0.5) (and you can change the rate)`\n",
    "`tf.keras.layers.BatchNormalization()`\n",
    "\n",
    "These are applied to `Dense` layers so need to come after them, e.g.: \n",
    "\n",
    "`keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='sigmoid'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])`\n",
    "\n",
    "You can change the loss function:\n",
    "dc.models.losses.L1Loss()\n",
    "dc.models.losses.L2Loss()\n",
    "dc.models.losses.L1Loss()\n",
    "dc.models.losses.SigmoidCrossEntropy()\n",
    "dc.models.losses.BinaryCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'pearson_r2_score': 0.8775775501057775}\n",
      "test set score: {'pearson_r2_score': 0.6360057260554358}\n"
     ]
    }
   ],
   "source": [
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model = dc.models.KerasModel(keras_model, dc.models.losses.L1Loss())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=50)\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'pearson_r2_score': 0.9775063817761833}\n",
      "test set score: {'pearson_r2_score': 0.7173285889782063}\n"
     ]
    }
   ],
   "source": [
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    #tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model = dc.models.KerasModel(keras_model, dc.models.losses.L2Loss())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=50)\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'pearson_r2_score': 0.9696253604768071}\n",
      "test set score: {'pearson_r2_score': 0.7318305561657411}\n"
     ]
    }
   ],
   "source": [
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(100, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model = dc.models.KerasModel(keras_model, dc.models.losses.L2Loss())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=50)\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))\n",
    "\n",
    "0.73-0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificiation\n",
    "\n",
    "A different network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_bace_classification(feturizer='ECFP', splitter='scaffold')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_bace_classification(feturizer='ECFP', splitter='scaffold')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'roc_auc_score': 0.9436893203883495}\n",
      "test set score: {'roc_auc_score': 0.7010869565217391}\n"
     ]
    }
   ],
   "source": [
    "classification_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "model = dc.models.KerasModel(classification_model, dc.models.losses.SigmoidCrossEntropy())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Make a better classification neural network\n",
    "\n",
    "Try modifying the NN below to see if you can improve the ROC score on the test set. \n",
    "\n",
    "the best I've managed is 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'roc_auc_score': 0.9588642872110078}\n",
      "test set score: {'roc_auc_score': 0.7554347826086956}\n"
     ]
    }
   ],
   "source": [
    "classification_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(500, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "model = dc.models.KerasModel(classification_model, dc.models.losses.SigmoidCrossEntropy())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'roc_auc_score': 0.9996060627226375}\n",
      "test set score: {'roc_auc_score': 0.7904438405797102}\n"
     ]
    }
   ],
   "source": [
    "classification_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    #tf.keras.layers.Dense(1,activation='softmax'),\n",
    "])\n",
    "model = dc.models.KerasModel(classification_model, dc.models.losses.BinaryCrossEntropy())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'roc_auc_score': 0.9996367954180345}\n",
      "test set score: {'roc_auc_score': 0.8480072463768116}\n"
     ]
    }
   ],
   "source": [
    "classification_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    #tf.keras.layers.Dense(1,activation='softmax'),\n",
    "])\n",
    "model = dc.models.KerasModel(classification_model, dc.models.losses.BinaryCrossEntropy())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: {'roc_auc_score': 0.9996340015366347}\n",
      "test set score: {'roc_auc_score': 0.8242753623188406}\n"
     ]
    }
   ],
   "source": [
    "classification_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    #tf.keras.layers.Dense(1,activation='softmax'),\n",
    "])\n",
    "model = dc.models.KerasModel(classification_model, dc.models.losses.BinaryCrossEntropy())\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric]))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting datasets to ensure a fair test\n",
    "\n",
    "splitters = ['random', 'scaffold', 'butina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitter: butina\n",
      "training set score: {'roc_auc_score': 0.9585322646171365}\n",
      "test set score: {'roc_auc_score': 0.6020360440656412}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_method = 'butina'\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='ECFP', splitter=split_method)\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "model = dc.models.MultitaskClassifier(n_tasks=len(tasks), n_features=1024, layer_sizes=[1000])\n",
    "model.fit(train_dataset, nb_epoch=10)\n",
    "print('splitter:', splitter)\n",
    "print('training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
    "print('test set score:', model.evaluate(test_dataset, [metric], transformers))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: try out the other options for splitting the dataset, which splitting method do you think is the best and why?\n",
    "\n",
    "You may want to run this a few times and think about what the splits mean, do you trust all of the answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitter: random\n",
      "training set score: {'roc_auc_score': 0.9545602678068751}\n",
      "test set score: {'roc_auc_score': 0.7862011607303782}\n",
      "\n",
      "splitter: scaffold\n",
      "training set score: {'roc_auc_score': 0.95877916613216}\n",
      "test set score: {'roc_auc_score': 0.6783032933872232}\n",
      "\n",
      "splitter: butina\n",
      "training set score: {'roc_auc_score': 0.9569020639243111}\n",
      "test set score: {'roc_auc_score': 0.6064522492487645}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitters = ['random', 'scaffold', 'butina']\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n",
    "for splitter in splitters:\n",
    "    tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='ECFP', splitter=splitter)\n",
    "    train_dataset, valid_dataset, test_dataset = datasets\n",
    "    model = dc.models.MultitaskClassifier(n_tasks=len(tasks), n_features=1024, layer_sizes=[1000])\n",
    "    model.fit(train_dataset, nb_epoch=10)\n",
    "    print('splitter:', splitter)\n",
    "    print('training set score:', model.evaluate(train_dataset, [metric], transformers))\n",
    "    print('test set score:', model.evaluate(test_dataset, [metric], transformers))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer*: The scaffold split seems to give the best solution. The random split results must be rejected because a random split can make the problem too easy if the dataset is not balanced (which this isn't) and the fact that it gives vastly better results than the other two methods suggests that the random split results overestimate the goodness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_tox21(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "n_tasks = len(tasks)\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.GraphConvModel(n_tasks, mode='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful information: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To see which datasets are available, run the code below.\n",
    "\n",
    "See also: https://deepchem.readthedocs.io/en/latest/api_reference/moleculenet.html \n",
    "which helpfully tells you the option you can use and the best splitter for that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['load_bace_classification',\n",
       " 'load_bace_regression',\n",
       " 'load_bandgap',\n",
       " 'load_bbbc001',\n",
       " 'load_bbbc002',\n",
       " 'load_bbbp',\n",
       " 'load_cell_counting',\n",
       " 'load_chembl',\n",
       " 'load_chembl25',\n",
       " 'load_clearance',\n",
       " 'load_clintox',\n",
       " 'load_delaney',\n",
       " 'load_factors',\n",
       " 'load_function',\n",
       " 'load_hiv',\n",
       " 'load_hopv',\n",
       " 'load_hppb',\n",
       " 'load_kaggle',\n",
       " 'load_kinase',\n",
       " 'load_lipo',\n",
       " 'load_mp_formation_energy',\n",
       " 'load_mp_metallicity',\n",
       " 'load_muv',\n",
       " 'load_nci',\n",
       " 'load_pcba',\n",
       " 'load_pdbbind',\n",
       " 'load_perovskite',\n",
       " 'load_ppb',\n",
       " 'load_qm7',\n",
       " 'load_qm8',\n",
       " 'load_qm9',\n",
       " 'load_sampl',\n",
       " 'load_sider',\n",
       " 'load_sweet',\n",
       " 'load_thermosol',\n",
       " 'load_tox21',\n",
       " 'load_toxcast',\n",
       " 'load_uspto',\n",
       " 'load_uv',\n",
       " 'load_zinc15']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[method for method in dir(dc.molnet) if \"load_\" in method ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
